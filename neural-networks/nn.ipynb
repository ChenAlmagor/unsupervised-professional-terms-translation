{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcc9F1H-T5S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall --quiet --yes tensorflow\n",
        "!pip install --quiet tensorflow-gpu==1.13.1\n",
        "!pip install --quiet tensorflow-hub\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet tf-sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPfwfXEfDAVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization\n",
        "import keras\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZMc7STlD4D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate data\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "def load_embeddings(emb_path):\n",
        "  data = []\n",
        "  with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
        "        for i, line in enumerate(f):\n",
        "                word, vect = line.rstrip().split(' ', 1)\n",
        "\n",
        "                word = word.lower()\n",
        "                vect = np.fromstring(vect, sep=' ')\n",
        "                if np.linalg.norm(vect) == 0:  # avoid to have null embeddings\n",
        "                    vect[0] = 0.01\n",
        "\n",
        "                else:\n",
        "                    if not vect.shape == (300,):\n",
        "                        print(\"Invalid dimension (%i) for word '%s' in line %i.\"\n",
        "                                       % (vect.shape[0], word, i))\n",
        "                        continue\n",
        "                    assert vect.shape == (300,), i\n",
        "                    data.append(vect)\n",
        "  return data\n",
        "\n",
        "d = np.array(load_embeddings('/content/supervision-init-full-new-dataset-en-emb.vec'))\n",
        "l = np.array(load_embeddings('/content/supervision-init-full-new-dataset-es-emb.vec'))\n",
        "\n",
        "data = d[:,]\n",
        "labels = l[:,]\n",
        "data_test = np.array(load_embeddings('/content/test-dict-only-words-en-emb.vec'))\n",
        "data_labels = np.array(load_embeddings('/content/test-dict-only-words-es-emb.vec'))\n",
        "\n",
        "src_embeddings = np.array(np.load('/content/200k-emb-en.npy'))\n",
        "tgt_embeddings = np.array(np.load('/content/200k-emb-es.npy'))\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(src_embeddings.shape)\n",
        "print(tgt_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawhtFcXa1fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(y_true, y_pred):\n",
        "  a = y_true \n",
        "  b = y_pred\n",
        "  normalize_a = tf.nn.l2_normalize(a)        \n",
        "  normalize_b = tf.nn.l2_normalize(b)\n",
        "  cos_similarity=tf.reduce_sum(tf.multiply(normalize_b, normalize_a))\n",
        "  return cos_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ivQalzqLq_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "FC_layer = Dense(300, activation='tanh', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "# FC_layer = Dense(300, activation='sigmoid', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "# FC_layer = Dense(300, activation='relu', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "# FC_layer = Dense(300, activation=keras.layers.LeakyReLU(alpha=0.3), input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "# BN_layer = BatchNormalization()\n",
        "\n",
        "model.add(FC_layer)\n",
        "\n",
        "\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(data[:, :], labels[:,:], epochs=80, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)\n",
        "TranslatedX = model.predict(src_embeddings)\n",
        "np.save('TranslatedX-tanh', TranslatedX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acuLKezBxl5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#linear (supervised)\n",
        "\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "model = Sequential()\n",
        "FC_layer = Dense(300, activation=None, input_dim=300, use_bias=False, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "\n",
        "\n",
        "model.add(FC_layer)\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data, labels, epochs=80, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yf4jdv3xHof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#init with linear\n",
        "T = np.load('/content/en_es_T.npy')\n",
        "T = np.transpose(T)\n",
        "\n",
        "\n",
        "def my_init(shape, dtype=None):\n",
        "    return T\n",
        "  \n",
        "\n",
        "model = Sequential()\n",
        "FC_layer = Dense(300, activation='relu', input_dim=300, use_bias=False, kernel_initializer=my_init)\n",
        "model.add(FC_layer)\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "model.fit(data, labels, epochs=50, batch_size=128)\n",
        "\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uJmPdEgz3vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deeper\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "FC_layer = Dense(300, activation='tanh', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "BN_layer = BatchNormalization()\n",
        "\n",
        "model.add(FC_layer)\n",
        "model.add(BN_layer)\n",
        "model.add(FC_layer)\n",
        "model.add(BN_layer)\n",
        "model.add(FC_layer)\n",
        "model.add(BN_layer)\n",
        "\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data, labels, epochs=50, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5fHvbQuwaDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#down-up\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Dense(50, activation='relu', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None)))\n",
        "model.add( BatchNormalization())\n",
        "model.add(Dense(300, activation='relu', input_dim=50, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None)))\n",
        "model.add( BatchNormalization())\n",
        "model.add(Dense(300, activation='relu', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None)))\n",
        "model.add( BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data[:,], labels[:,], epochs=200, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CwnS-5_3u9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#linear+relu\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "FC_layer = Dense(300, activation='linear', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "BN_layer = BatchNormalization()\n",
        "FC_layer_relu = Dense(300, activation='relu', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "\n",
        "model.add(FC_layer)\n",
        "model.add(BN_layer)\n",
        "model.add(FC_layer_relu)\n",
        "model.add(BN_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#just changing the lr\n",
        "adam = keras.optimizers.Adam(lr=1e-2, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data, labels, epochs=200, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QajCHEng6Hyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sgd\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "FC_layer = Dense(300, activation='linear', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "BN_layer = BatchNormalization()\n",
        "FC_layer_relu = Dense(300, activation='relu', input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "\n",
        "model.add(FC_layer)\n",
        "model.add(BN_layer)\n",
        "model.add(FC_layer_relu)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data, labels, epochs=200, batch_size=128)\n",
        "model.evaluate(data_test, data_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRLwxl1O0GDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just changing the lr\n",
        "from tensorflow.python.keras import metrics\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "FC_layer = Dense(300, activation=None, input_dim=300, use_bias=True, kernel_initializer = keras.initializers.glorot_uniform(seed=None))\n",
        "\n",
        "model.add(FC_layer)\n",
        "\n",
        "\n",
        "#just changing the lr\n",
        "adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.5, beta_2=0.999)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='mse',\n",
        "              metrics=[cosine_similarity, 'acc'])\n",
        "\n",
        "model.fit(data, labels, epochs=50, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}